# YouTube Watch History Analysis for Portfolio Project

This project analyzes YouTube watch history data to demonstrate skills in data cleaning, semantic analysis, and preparation for Large Language Model (LLM) fine-tuning.

## Project Structure

- `data/`: Contains the raw `watch-history.html` (user-provided) and the `cleaned_watch_history.csv` generated by the first notebook. It will also store `video_transcripts.jsonl` if notebook 06 is run.
- `notebooks/`: Contains the Jupyter notebooks for each stage of the analysis.
    - `01_data_cleaning.ipynb`: Loads the raw `watch-history.html`, parses it, cleans the data (timestamps, duplicates, etc.), and saves the result to `cleaned_watch_history.csv`.
    - `02_semantic_analysis.ipynb`: Performs exploratory data analysis (EDA) on the cleaned watch history, including identifying top channels and viewing patterns. It also conducts semantic analysis on video titles using TF-IDF and Latent Dirichlet Allocation (LDA) for topic modeling.
    - `03_llm_training.ipynb`: Prepares the video title data for potential fine-tuning of a Large Language Model. This includes tokenization using Hugging Face `transformers` and provides a commented outline for the model training process.
    - `04_lightweight_llm_training.ipynb`: Demonstrates fine-tuning a lightweight Large Language Model (DistilGPT2) on the cleaned video titles for text generation. It includes data preparation, a basic training loop (CPU-based), model saving, and an example of generating new text based on prompts.
    - `05_advanced_llm_training_m1.ipynb`: Implements fine-tuning for a more powerful LLM (GPT-2, 124M parameters) specifically targeting Apple Silicon (M1/M2/M3) Macs with MPS for GPU acceleration. It includes device checking, data preparation, a training loop configured for MPS, model saving, and text generation. This notebook demonstrates a more resource-intensive training process compared to the DistilGPT2 example.
    - `06_transcript_llm_training.ipynb`: An advanced notebook that attempts to fetch full video transcripts using the `youtube-transcript-api` and then fine-tunes GPT-2 on this transcript data. It includes transcript fetching with error handling, data preparation for long text, and fine-tuning/inference on an MPS-enabled device (e.g., M1/M2/M3 Mac). **This notebook is highly experimental and resource-intensive.** It's crucial to start with a very small number of videos (by adjusting `MAX_VIDEOS_TO_PROCESS` within the notebook).

## Setup and Dependencies

To run these notebooks, you'll need Python 3 and the following libraries. You can install them using pip:

```bash
pip install pandas beautifulsoup4 matplotlib seaborn nltk scikit-learn transformers torch youtube-transcript-api
```

You will also need to download NLTK resources. Run this in a Python interpreter within your environment after installing nltk:

```python
import nltk
nltk.download('stopwords')
nltk.download('punkt')
```
For Apple Silicon (M1/M2/M3) users wanting to use MPS for GPU acceleration, ensure you install the correct PyTorch version as detailed in the "Important Note for Apple Silicon Users" section below.

## How to Run

1.  Place your `watch-history.html` file (obtained from your Google Takeout) into the `youtube_analysis/data/` directory.
2.  Run the notebooks sequentially:
    *   Start with `01_data_cleaning.ipynb` to process your history.
    *   Then, run `02_semantic_analysis.ipynb` for EDA and topic modeling.
    *   Next, explore `03_llm_training.ipynb` for the LLM data preparation steps.
    *   Optionally, run `04_lightweight_llm_training.ipynb` to experiment with fine-tuning DistilGPT2 and generating text. Be aware that training even this lightweight model can take some time on a CPU.
    *   For users with Apple Silicon (M1/M2/M3) Macs, `05_advanced_llm_training_m1.ipynb` provides an example of fine-tuning GPT-2 using MPS. Ensure your PyTorch environment is correctly set up for MPS. Training this model will take significantly longer and use more resources than notebook 04.
    *   Notebook `06_transcript_llm_training.ipynb` offers an experimental approach to fine-tune GPT-2 on full video transcripts. **Use with caution due to high resource demand and long processing times.** Before running, ensure `youtube-transcript-api` is installed (as listed in dependencies). Critically, modify the `MAX_VIDEOS_TO_PROCESS` variable inside the notebook to a very small number (e.g., 5-10) for initial runs. Expect this notebook to take a very long time, even for a small number of videos, especially the transcript fetching and LLM training stages.

## Notes

- The LLM training part (`03_llm_training.ipynb`) currently only sets up data preparation and provides a placeholder for training. Actual LLM fine-tuning is computationally intensive and may require a GPU and further environment configuration.
- The LLM fine-tuning in `04_lightweight_llm_training.ipynb` uses a small model (DistilGPT2) and a very limited number of training epochs on the CPU. The primary purpose is to demonstrate the process. Generated text quality will be basic and is intended as an illustration rather than a production-ready model. For more advanced results, larger models, more data, and GPU resources would be necessary.
- The quality of semantic analysis and topic modeling can be further improved by more advanced text preprocessing, hyperparameter tuning for LDA, and exploring different embedding techniques.
- **Regarding `06_transcript_llm_training.ipynb` (Transcript Fine-tuning):**
    - This notebook is the most resource-intensive. It fetches transcripts via `youtube-transcript-api`, which can be slow and is dependent on transcript availability and quality for each video.
    - **Start with `MAX_VIDEOS_TO_PROCESS` set to a very low number (e.g., 5-10) within the notebook.** Attempting to process hundreds of videos will take an extremely long time and may exhaust resources or lead to API rate-limiting.
    - Fine-tuning GPT-2 on concatenated transcripts, even for a few videos, will require significant time and memory, even with MPS acceleration.
    - The quality of the fine-tuned model will heavily depend on the amount and quality of the transcript data successfully fetched and processed.
    - Note: The transcript fetching logic in `06_transcript_llm_training.ipynb` uses exception handling that targets recent versions of the `youtube-transcript-api`. If you encounter import errors related to specific exceptions from this library, or issues with transcript fetching, you may need to adjust the `try...except` blocks in that notebook to match the version you have installed or consult the API's documentation for the latest exception types.

### Important Note for Apple Silicon (M1/M2/M3) Users

- **PyTorch with MPS:** To run the training in `05_advanced_llm_training_m1.ipynb` and `06_transcript_llm_training.ipynb` (and to accelerate other PyTorch tasks like in `03_llm_training.ipynb` or `04_lightweight_llm_training.ipynb` if you adapt them for MPS), you **must** have a version of PyTorch installed that supports Apple's Metal Performance Shaders (MPS).
    - Install the latest stable PyTorch version following instructions from the [official PyTorch website](https://pytorch.org/get-started/locally/) (select the appropriate options for your Mac, typically "Stable", "macOS", "Python", and "Default" or "MPS").
    - Notebooks `05` and `06` include code to automatically detect and use MPS if available.
- **Resource Usage for `05_advanced_llm_training_m1.ipynb` and `06_transcript_llm_training.ipynb`:** Fine-tuning GPT-2 is considerably more demanding than DistilGPT2. Expect longer training times (even with MPS) and higher memory consumption. The provided settings (e.g., batch size, epochs) are starting points and may need adjustment based on your specific M1/M2/M3 configuration (Pro, Max, Ultra, RAM).
- The earlier notebooks (`01` to `04`) are designed to be more generally compatible and will run on CPU if MPS is not configured or if you are not on Apple Silicon.
```
